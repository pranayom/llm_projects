{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-Benefit Analysis: Adversarial Fraud Detection\n",
    "\n",
    "This notebook performs Monte Carlo simulation to quantify the business value of adversarial robustness testing.\n",
    "\n",
    "## Key Questions\n",
    "1. What is the expected loss from adversarial attacks on our fraud detection system?\n",
    "2. How much does improving model robustness reduce expected losses?\n",
    "3. What is the ROI of red team testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Business Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business parameters\n",
    "PARAMS = {\n",
    "    # Transaction volume\n",
    "    'daily_transactions': 100_000,\n",
    "    'fraud_rate': 0.0013,  # 0.13% from PaySim data\n",
    "    'avg_fraud_amount': 25_000,  # Average fraudulent transaction amount\n",
    "    \n",
    "    # Model performance\n",
    "    'model_auc': 0.9989,\n",
    "    'detection_rate': 0.95,  # True positive rate at operating threshold\n",
    "    'false_positive_rate': 0.01,\n",
    "    \n",
    "    # Adversarial risk (before robustness testing)\n",
    "    'evasion_rate_before': 0.20,  # 20% of attacks succeed\n",
    "    'attacker_sophistication': 0.05,  # 5% of fraudsters use adversarial techniques\n",
    "    \n",
    "    # After robustness improvements\n",
    "    'evasion_rate_after': 0.05,  # Reduced to 5% after improvements\n",
    "    \n",
    "    # Costs\n",
    "    'cost_per_fraud': 25_000,  # Direct loss per undetected fraud\n",
    "    'cost_per_fp': 50,  # Customer friction cost per false positive\n",
    "    'red_team_cost': 50_000,  # Annual cost of red team program\n",
    "    'remediation_cost': 100_000,  # One-time cost to improve model\n",
    "}\n",
    "\n",
    "print(\"Business Parameters:\")\n",
    "for k, v in PARAMS.items():\n",
    "    print(f\"  {k}: {v:,}\" if isinstance(v, int) else f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monte Carlo Simulation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_annual_losses(params, evasion_rate, n_simulations=10000):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation of annual fraud losses.\n",
    "    \n",
    "    Returns array of simulated annual losses.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Daily fraud attempts (Poisson distributed)\n",
    "        daily_frauds = np.random.poisson(\n",
    "            params['daily_transactions'] * params['fraud_rate'],\n",
    "            365\n",
    "        )\n",
    "        \n",
    "        annual_fraud_attempts = daily_frauds.sum()\n",
    "        \n",
    "        # Split into regular and adversarial attacks\n",
    "        adversarial_attacks = int(annual_fraud_attempts * params['attacker_sophistication'])\n",
    "        regular_attacks = annual_fraud_attempts - adversarial_attacks\n",
    "        \n",
    "        # Detection outcomes\n",
    "        # Regular attacks: detected at model's detection rate\n",
    "        regular_missed = np.random.binomial(regular_attacks, 1 - params['detection_rate'])\n",
    "        \n",
    "        # Adversarial attacks: affected by evasion rate\n",
    "        adversarial_evaded = np.random.binomial(adversarial_attacks, evasion_rate)\n",
    "        adversarial_detected = adversarial_attacks - adversarial_evaded\n",
    "        adversarial_missed = adversarial_evaded + np.random.binomial(\n",
    "            adversarial_detected, 1 - params['detection_rate']\n",
    "        )\n",
    "        \n",
    "        # Total undetected fraud\n",
    "        total_missed = regular_missed + adversarial_missed\n",
    "        \n",
    "        # Calculate losses (with variance in fraud amounts)\n",
    "        fraud_amounts = np.random.lognormal(\n",
    "            np.log(params['avg_fraud_amount']),\n",
    "            0.5,\n",
    "            total_missed\n",
    "        )\n",
    "        fraud_loss = fraud_amounts.sum()\n",
    "        \n",
    "        # False positive costs\n",
    "        legitimate_txns = params['daily_transactions'] * 365 * (1 - params['fraud_rate'])\n",
    "        false_positives = int(legitimate_txns * params['false_positive_rate'])\n",
    "        fp_cost = false_positives * params['cost_per_fp']\n",
    "        \n",
    "        total_loss = fraud_loss + fp_cost\n",
    "        results.append({\n",
    "            'fraud_loss': fraud_loss,\n",
    "            'fp_cost': fp_cost,\n",
    "            'total_loss': total_loss,\n",
    "            'frauds_missed': total_missed,\n",
    "            'adversarial_evaded': adversarial_missed\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Simulations: Before vs After Robustness Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Monte Carlo simulations (10,000 iterations each)...\")\n",
    "\n",
    "# Simulate before improvements\n",
    "results_before = simulate_annual_losses(PARAMS, PARAMS['evasion_rate_before'])\n",
    "print(f\"\\nBefore robustness improvements (evasion rate: {PARAMS['evasion_rate_before']:.0%})\")\n",
    "\n",
    "# Simulate after improvements\n",
    "results_after = simulate_annual_losses(PARAMS, PARAMS['evasion_rate_after'])\n",
    "print(f\"After robustness improvements (evasion rate: {PARAMS['evasion_rate_after']:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(df, label):\n",
    "    \"\"\"Print summary statistics for simulation results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nAnnual Fraud Losses:\")\n",
    "    print(f\"  Mean:   ${df['fraud_loss'].mean():,.0f}\")\n",
    "    print(f\"  Median: ${df['fraud_loss'].median():,.0f}\")\n",
    "    print(f\"  Std:    ${df['fraud_loss'].std():,.0f}\")\n",
    "    print(f\"  95th:   ${df['fraud_loss'].quantile(0.95):,.0f}\")\n",
    "    print(f\"  99th:   ${df['fraud_loss'].quantile(0.99):,.0f}\")\n",
    "    \n",
    "    print(f\"\\nFrauds Missed per Year:\")\n",
    "    print(f\"  Mean: {df['frauds_missed'].mean():,.0f}\")\n",
    "    print(f\"  From adversarial attacks: {df['adversarial_evaded'].mean():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nTotal Annual Cost (fraud + FP):\")\n",
    "    print(f\"  Mean: ${df['total_loss'].mean():,.0f}\")\n",
    "\n",
    "summarize_results(results_before, \"BEFORE Robustness Improvements\")\n",
    "summarize_results(results_after, \"AFTER Robustness Improvements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate ROI of Red Team Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate savings\n",
    "annual_savings = results_before['total_loss'].mean() - results_after['total_loss'].mean()\n",
    "total_investment = PARAMS['red_team_cost'] + PARAMS['remediation_cost']\n",
    "\n",
    "# ROI calculation\n",
    "roi = (annual_savings - total_investment) / total_investment * 100\n",
    "payback_months = total_investment / (annual_savings / 12)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ROI ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAnnual Loss Reduction: ${annual_savings:,.0f}\")\n",
    "print(f\"\\nInvestment:\")\n",
    "print(f\"  Red Team Program: ${PARAMS['red_team_cost']:,}\")\n",
    "print(f\"  Model Remediation: ${PARAMS['remediation_cost']:,}\")\n",
    "print(f\"  Total: ${total_investment:,}\")\n",
    "print(f\"\\nFirst Year ROI: {roi:.1f}%\")\n",
    "print(f\"Payback Period: {payback_months:.1f} months\")\n",
    "\n",
    "# 5-year NPV calculation (10% discount rate)\n",
    "discount_rate = 0.10\n",
    "years = 5\n",
    "npv = -total_investment + sum(\n",
    "    (annual_savings - PARAMS['red_team_cost']) / (1 + discount_rate)**year\n",
    "    for year in range(1, years + 1)\n",
    ")\n",
    "print(f\"\\n5-Year NPV (10% discount): ${npv:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of annual losses\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(results_before['fraud_loss'] / 1e6, bins=50, alpha=0.6, label='Before', color='red')\n",
    "ax1.hist(results_after['fraud_loss'] / 1e6, bins=50, alpha=0.6, label='After', color='green')\n",
    "ax1.axvline(results_before['fraud_loss'].mean() / 1e6, color='red', linestyle='--', label='Mean (Before)')\n",
    "ax1.axvline(results_after['fraud_loss'].mean() / 1e6, color='green', linestyle='--', label='Mean (After)')\n",
    "ax1.set_xlabel('Annual Fraud Loss ($ millions)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Annual Fraud Losses')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Box plot comparison\n",
    "ax2 = axes[0, 1]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Before': results_before['fraud_loss'] / 1e6,\n",
    "    'After': results_after['fraud_loss'] / 1e6\n",
    "})\n",
    "comparison_df.boxplot(ax=ax2)\n",
    "ax2.set_ylabel('Annual Fraud Loss ($ millions)')\n",
    "ax2.set_title('Fraud Loss Comparison')\n",
    "\n",
    "# 3. Cumulative distribution\n",
    "ax3 = axes[1, 0]\n",
    "sorted_before = np.sort(results_before['fraud_loss'])\n",
    "sorted_after = np.sort(results_after['fraud_loss'])\n",
    "p = np.linspace(0, 1, len(sorted_before))\n",
    "ax3.plot(sorted_before / 1e6, p, label='Before', color='red')\n",
    "ax3.plot(sorted_after / 1e6, p, label='After', color='green')\n",
    "ax3.axhline(0.95, color='gray', linestyle=':', alpha=0.5)\n",
    "ax3.axhline(0.99, color='gray', linestyle=':', alpha=0.5)\n",
    "ax3.set_xlabel('Annual Fraud Loss ($ millions)')\n",
    "ax3.set_ylabel('Cumulative Probability')\n",
    "ax3.set_title('Loss Distribution (CDF)')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. ROI waterfall\n",
    "ax4 = axes[1, 1]\n",
    "categories = ['Loss\\nBefore', 'Savings', 'Investment', 'Net\\nBenefit']\n",
    "values = [\n",
    "    results_before['fraud_loss'].mean() / 1e6,\n",
    "    -annual_savings / 1e6,\n",
    "    total_investment / 1e6,\n",
    "    (annual_savings - total_investment) / 1e6\n",
    "]\n",
    "colors = ['red', 'green', 'orange', 'blue']\n",
    "ax4.bar(categories, values, color=colors)\n",
    "ax4.axhline(0, color='black', linewidth=0.5)\n",
    "ax4.set_ylabel('$ millions')\n",
    "ax4.set_title('Annual Financial Impact')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/cost_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved to outputs/cost_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different evasion rate improvements\n",
    "evasion_rates = [0.25, 0.20, 0.15, 0.10, 0.05, 0.02]\n",
    "savings_by_rate = []\n",
    "\n",
    "print(\"Sensitivity Analysis: Savings vs Evasion Rate\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "baseline_loss = results_before['total_loss'].mean()\n",
    "\n",
    "for rate in evasion_rates:\n",
    "    sim = simulate_annual_losses(PARAMS, rate, n_simulations=1000)\n",
    "    avg_loss = sim['total_loss'].mean()\n",
    "    savings = baseline_loss - avg_loss\n",
    "    savings_by_rate.append(savings)\n",
    "    print(f\"  Evasion rate {rate:5.0%}: Annual savings ${savings:>12,.0f}\")\n",
    "\n",
    "# Plot sensitivity\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([r * 100 for r in evasion_rates], [s / 1e6 for s in savings_by_rate], 'bo-', linewidth=2, markersize=8)\n",
    "plt.axhline(total_investment / 1e6, color='red', linestyle='--', label=f'Investment (${total_investment/1e6:.1f}M)')\n",
    "plt.xlabel('Evasion Rate After Improvements (%)')\n",
    "plt.ylabel('Annual Savings ($ millions)')\n",
    "plt.title('Sensitivity: Savings vs Achieved Evasion Rate')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().invert_xaxis()  # Lower evasion rate = better\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/sensitivity_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         EXECUTIVE SUMMARY                                    ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  BUSINESS CONTEXT                                                            ║\n",
    "║  • Daily transaction volume: 100,000 transactions                            ║\n",
    "║  • Baseline fraud rate: 0.13%                                                ║\n",
    "║  • Average fraud transaction: $25,000                                        ║\n",
    "║  • Adversarial attacker prevalence: 5% of fraudsters                        ║\n",
    "║                                                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  KEY FINDINGS                                                                ║\"\"\")\n",
    "\n",
    "print(f\"\"\"║  • Expected annual fraud loss (before): ${results_before['fraud_loss'].mean():>15,.0f}         ║\n",
    "║  • Expected annual fraud loss (after):  ${results_after['fraud_loss'].mean():>15,.0f}         ║\n",
    "║  • Annual loss reduction:               ${annual_savings:>15,.0f}         ║\n",
    "║  • Investment required:                 ${total_investment:>15,}         ║\n",
    "║  • First-year ROI:                      {roi:>15.1f}%        ║\n",
    "║  • Payback period:                      {payback_months:>13.1f} months       ║\n",
    "║  • 5-year NPV:                          ${npv:>15,.0f}         ║\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "║                                                                              ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  RECOMMENDATION                                                              ║\n",
    "║  Implement adversarial red team testing program. The investment pays for     ║\n",
    "║  itself within the first year and provides ongoing protection against        ║\n",
    "║  sophisticated fraud attacks.                                                ║\n",
    "║                                                                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Assumptions & Limitations\n",
    "\n",
    "**Assumptions:**\n",
    "- Fraud attempts follow a Poisson distribution\n",
    "- Fraud amounts follow a log-normal distribution\n",
    "- Adversarial attackers represent 5% of total fraudsters\n",
    "- Model performance remains stable over the analysis period\n",
    "\n",
    "**Limitations:**\n",
    "- Does not account for regulatory fines or reputational damage\n",
    "- Assumes constant attacker sophistication over time\n",
    "- Does not model adaptive attackers who learn from failures\n",
    "\n",
    "**Data Sources:**\n",
    "- PaySim synthetic dataset for fraud rate baseline\n",
    "- Red team campaign results for evasion rate estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
