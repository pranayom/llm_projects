{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from st_diff_viewer import diff_viewer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "from PyPDF2 import PdfReader\n",
    "import time\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type\n",
    ")\n",
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "# Configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "def num_tokens(text):\n",
    "    \"\"\"Count tokens using tiktoken\"\"\"\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "# Tokenizer for GPT-4\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Custom theme and session state initialization\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    [data-testid=stSidebar] {\n",
    "        background-color: #f0f2f6;\n",
    "    }\n",
    "    .stProgress > div > div > div > div {\n",
    "        background-color: #4B8BF5;\n",
    "    }\n",
    "    .st-b7 {\n",
    "        color: #262730;\n",
    "    }\n",
    "    .report-section { \n",
    "        border-left: 4px solid #4B8BF5;\n",
    "        padding-left: 1rem;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Retry configuration for rate limits\n",
    "def retriable_chain_invoke(chain, inputs):\n",
    "    return chain.invoke(inputs)\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    retry=retry_if_exception_type(openai.RateLimitError),\n",
    "    reraise=True\n",
    ")\n",
    "def retriable_chain_invoke(chain, inputs):\n",
    "    \"\"\"Wrapper with retry logic for OpenAI API calls\"\"\"\n",
    "    return chain.invoke(inputs)\n",
    "\n",
    "def num_tokens(text):\n",
    "    \"\"\"Calculate token count for text\"\"\"\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def extract_text(file):\n",
    "    \"\"\"Extract text from DOCX or PDF files\"\"\"\n",
    "    if file.name.endswith('.docx'):\n",
    "        return docx2txt.process(file)\n",
    "    elif file.name.endswith('.pdf'):\n",
    "        reader = PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def process_document(file, doc_type, year):\n",
    "    \"\"\"Process document into chunks with metadata\"\"\"\n",
    "    text = extract_text(file)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return [{\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"source\": file.name,\n",
    "            \"doc_type\": doc_type,\n",
    "            \"year\": year,\n",
    "            \"page\": (idx // 10) + 1\n",
    "        }\n",
    "    } for idx, chunk in enumerate(chunks)]\n",
    "\n",
    "def analyze_changes(doc1_chunks, doc2_chunks):\n",
    "    \"\"\"Analyze documents using FAISS embeddings with rate limit handling\"\"\"\n",
    "    embeddings = OpenAIEmbeddings(chunk_size=10)  # Smaller chunk size for rate limiting\n",
    "    \n",
    "    doc1_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) \n",
    "                for c in doc1_chunks]\n",
    "    doc2_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) \n",
    "                for c in doc2_chunks]\n",
    "\n",
    "    # Create vector stores with error handling\n",
    "    db1 = FAISS.from_documents(doc1_docs, embeddings)\n",
    "    time.sleep(1)  # Rate limit buffer\n",
    "    db2 = FAISS.from_documents(doc2_docs, embeddings)\n",
    "\n",
    "    changes = {\"added\": [], \"removed\": [], \"modified\": []}\n",
    "\n",
    "    # Batch processing for rate limiting\n",
    "    batch_size = 5\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"added\"].append({\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata\n",
    "                })\n",
    "        time.sleep(1)\n",
    "\n",
    "    for i in range(0, len(doc1_docs), batch_size):\n",
    "        batch = doc1_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db2.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"removed\"].append({\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata\n",
    "                })\n",
    "        time.sleep(1)\n",
    "\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if similar and similar[0].metadata[\"source\"] == doc.metadata[\"source\"]:\n",
    "                doc1 = similar[0]\n",
    "                if doc1.page_content != doc.page_content:\n",
    "                    changes[\"modified\"].append({\n",
    "                        \"original\": doc1.page_content,\n",
    "                        \"updated\": doc.page_content,\n",
    "                        \"metadata\": doc.metadata\n",
    "                    })\n",
    "        time.sleep(1)\n",
    "\n",
    "    return changes\n",
    "\n",
    "def generate_executive_summary(changes, doc1_meta, doc2_meta):\n",
    "    \"\"\"Generate human-readable summary with hierarchical processing\"\"\"\n",
    "    # 1. Cluster related changes using embeddings\n",
    "    cluster_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Cluster these document changes into logical groups based on semantic similarity:\n",
    "    {changes}\n",
    "    \n",
    "    Return ONLY a JSON array of cluster objects with:\n",
    "    - \"theme\": Short descriptive title\n",
    "    - \"change_ids\": Array of original change indices\n",
    "    - \"key_phrases\": 3-5 key phrases per cluster\n",
    "    \"\"\")\n",
    "    \n",
    "    # 2. Hierarchical summarization chain\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    As a professional analyst, create an executive summary comparing:\n",
    "    {doc1} ({year1}) vs {doc2} ({year2}).\n",
    "    \n",
    "    Key clustered changes:\n",
    "    {clustered_changes}\n",
    "\n",
    "    Structure:\n",
    "    1. **Major Structural Changes** (sections added/removed)\n",
    "    2. **Content Evolution** (modified themes and concepts)\n",
    "    3. **Strategic Implications** (business impact analysis)\n",
    "    4. **Recommendations** (next steps based on changes)\n",
    "    \n",
    "    Include specific examples with citations like: \n",
    "    \"The address changed from [X][p3] to [Y][p12]\" \n",
    "    Use markdown with section headers and bold key terms.\n",
    "    \"\"\")\n",
    "\n",
    "    # Implementation steps\n",
    "    cluster_chain = cluster_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "    summary_chain = summary_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "    # Process in batches using research-backed methods [1][3][5]\n",
    "    def chunk_changes(changes, max_tokens=6000):\n",
    "        current_chunk = []\n",
    "        current_count = 0\n",
    "        for idx, item in enumerate(changes):\n",
    "            item_tokens = num_tokens(item['content'])\n",
    "            if current_count + item_tokens > max_tokens:\n",
    "                yield current_chunk\n",
    "                current_chunk = []\n",
    "                current_count = 0\n",
    "            current_chunk.append((idx, item))\n",
    "            current_count += item_tokens\n",
    "        if current_chunk:\n",
    "            yield current_chunk\n",
    "\n",
    "    # Cluster changes using hierarchical approach [8]\n",
    "    all_clusters = []\n",
    "    for chunk in chunk_changes(\n",
    "        [c for cat in changes.values() for c in cat], \n",
    "        max_tokens=6000\n",
    "    ):\n",
    "        cluster_result = retriable_chain_invoke(cluster_chain, {\n",
    "            \"changes\": \"\\n\".join(\n",
    "                f\"{idx}: {item['content'][:500]}...\" \n",
    "                for idx, item in chunk\n",
    "            )\n",
    "        })\n",
    "        all_clusters.extend(json.loads(cluster_result.content))\n",
    "    \n",
    "    # Process clusters with context-aware summarization [1][4][6]\n",
    "    cluster_summaries = []\n",
    "    for cluster in all_clusters:\n",
    "        cluster_changes = [changes[i] for i in cluster[\"change_ids\"]]\n",
    "        cluster_text = \"\\n\".join(\n",
    "            f\"Change {i}: {c['content'][:1000]} [Source: {c['metadata']['source']}, Page {c['metadata']['page']}]\"\n",
    "            for i, c in zip(cluster[\"change_ids\"], cluster_changes)\n",
    "        )\n",
    "        \n",
    "        cluster_summary = retriable_chain_invoke(summary_chain, {\n",
    "            \"doc1\": doc1_meta[\"name\"],\n",
    "            \"year1\": doc1_meta[\"year\"],\n",
    "            \"doc2\": doc2_meta[\"name\"],\n",
    "            \"year2\": doc2_meta[\"year\"],\n",
    "            \"clustered_changes\": cluster_text\n",
    "        })\n",
    "        cluster_summaries.append(cluster_summary.content)\n",
    "        time.sleep(1)  # Rate limit buffer\n",
    "\n",
    "    # Final consolidation with cross-cluster analysis [8]\n",
    "    final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Synthesize these cluster summaries into an executive report:\n",
    "    {cluster_summaries}\n",
    "\n",
    "    Maintain this structure:\n",
    "    1. **Document Evolution Overview**\n",
    "    2. **Strategic Direction Analysis**\n",
    "    3. **Operational Impact Assessment**\n",
    "    4. **Recommendations for Future Versions**\n",
    "\n",
    "    Include 3-5 key visualizable trends using **bold** terms.\n",
    "    Cite sources like [Source: {source}, Page {page}].\n",
    "    \"\"\")\n",
    "\n",
    "    final_chain = final_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "    final_summary = retriable_chain_invoke(final_chain, {\n",
    "        \"cluster_summaries\": \"\\n\\n\".join(cluster_summaries)\n",
    "    })\n",
    "    return final_summary.content, all_clusters\n",
    "\n",
    "def chunked_report_generator(changes, max_tokens=12000):\n",
    "    \"\"\"Split changes into token-sized chunks for GPT processing\"\"\"\n",
    "    current_chunk = []\n",
    "    current_count = 0\n",
    "    \n",
    "    for cat in ['added', 'removed', 'modified']:\n",
    "        for item in changes[cat]:\n",
    "            content = f\"{cat.upper()}:\\n{item['content']}\\n\"\n",
    "            tokens = num_tokens(content)\n",
    "            \n",
    "            if current_count + tokens > max_tokens:\n",
    "                yield current_chunk\n",
    "                current_chunk = []\n",
    "                current_count = 0\n",
    "                \n",
    "            current_chunk.append(content)\n",
    "            current_count += tokens\n",
    "    \n",
    "    if current_chunk:\n",
    "        yield current_chunk\n",
    "\n",
    "def generate_detailed_report(changes, doc1_meta, doc2_meta):\n",
    "    \"\"\"Generate detailed report with chunked processing\"\"\"\n",
    "    report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Analyze document changes between:\n",
    "    {doc1} ({year1}) and {doc2} ({year2})\n",
    "\n",
    "    Changes:\n",
    "    {changes}\n",
    "\n",
    "    Format requirements:\n",
    "    - Group by ADDED/REMOVED/MODIFIED\n",
    "    - Include citations like [Source: {source}, Page {page}]\n",
    "    - Highlight significant changes with **bold**\n",
    "    - Use markdown headers ##\n",
    "    - Maintain academic tone\n",
    "    \"\"\")\n",
    "    \n",
    "    full_report = []\n",
    "    chain = report_prompt | ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "    \n",
    "    for chunk in chunked_report_generator(changes):\n",
    "        part = retriable_chain_invoke(chain, {\n",
    "            \"doc1\": doc1_meta[\"name\"],\n",
    "            \"year1\": doc1_meta[\"year\"],\n",
    "            \"doc2\": doc2_meta[\"name\"],\n",
    "            \"year2\": doc2_meta[\"year\"],\n",
    "            \"changes\": \"\\n\".join(chunk)\n",
    "        }).content\n",
    "        full_report.append(part)\n",
    "        time.sleep(2)  # Rate limit buffer\n",
    "    \n",
    "    return \"\\n\\n\".join(full_report)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Professional Document Comparison Suite\")\n",
    "    \n",
    "    # Session state initialization\n",
    "    if 'colors' not in st.session_state:\n",
    "        st.session_state.colors = {\n",
    "            'added': '#d4f7d4',\n",
    "            'removed': '#f7d4d4',\n",
    "            'modified': '#fff3d4'\n",
    "        }\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header(\"Configuration\")\n",
    "        st.session_state.colors['added'] = st.color_picker(\"Added Color\", '#d4f7d4')\n",
    "        st.session_state.colors['removed'] = st.color_picker(\"Removed Color\", '#f7d4d4')\n",
    "        st.session_state.colors['modified'] = st.color_picker(\"Modified Color\", '#fff3d4')\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        doc1 = st.file_uploader(\"Upload Baseline Document\", type=[\"pdf\", \"docx\"])\n",
    "        year1 = st.number_input(\"Baseline Year\", min_value=1900, max_value=2025, value=2023)\n",
    "    with col2:\n",
    "        doc2 = st.file_uploader(\"Upload Comparison Document\", type=[\"pdf\", \"docx\"])\n",
    "        year2 = st.number_input(\"Comparison Year\", min_value=1900, max_value=2025, value=2024)\n",
    "\n",
    "    if st.button(\"Analyze Documents\") and doc1 and doc2:\n",
    "        with st.status(\"Processing documents...\", expanded=True) as status:\n",
    "            try:\n",
    "                # Process documents\n",
    "                st.write(\"📄 Processing Document 1...\")\n",
    "                doc1_chunks = process_document(doc1, doc1.name.split('.')[-1], year1)\n",
    "                \n",
    "                st.write(\"📄 Processing Document 2...\")\n",
    "                doc2_chunks = process_document(doc2, doc2.name.split('.')[-1], year2)\n",
    "                \n",
    "                # Analyze changes\n",
    "                st.write(\"🔍 Analyzing differences...\")\n",
    "                changes = analyze_changes(doc1_chunks, doc2_chunks)\n",
    "                \n",
    "                # Generate reports\n",
    "                st.write(\"📊 Generating summary...\")\n",
    "                summary, all_clusters = generate_executive_summary(  # Unpack tuple\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    ")\n",
    "                \n",
    "                st.write(\"📝 Compiling detailed report...\")\n",
    "                detailed_report = generate_detailed_report(\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    "                )\n",
    "                \n",
    "                # Combine reports\n",
    "                full_report = f\"# Document Comparison Report\\n{summary}\\n{detailed_report}\"\n",
    "                \n",
    "                status.update(label=\"Analysis complete! ✅\", state=\"complete\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"❌ Processing failed: {str(e)}\")\n",
    "                return\n",
    "\n",
    "        # Visualization\n",
    "        with st.expander(\"Detailed Analysis\", expanded=True):\n",
    "            tab1, tab2, tab3, tab4 = st.tabs([\"Diff View\", \"Statistics\", \"Full Report\", \"Executive Summary\"])\n",
    "            \n",
    "            with tab1:\n",
    "                diff_viewer(\n",
    "                    \"\\n\".join([c[\"content\"] for c in changes[\"removed\"]]),\n",
    "                    \"\\n\".join([c[\"content\"] for c in changes[\"added\"]]),\n",
    "                    split_view=True,\n",
    "                    added_style=f\"background: {st.session_state.colors['added']}\",\n",
    "                    removed_style=f\"background: {st.session_state.colors['removed']}\",\n",
    "                    modified_style=f\"background: {st.session_state.colors['modified']}\"\n",
    "                )\n",
    "            \n",
    "            with tab2:\n",
    "                stats = pd.DataFrame({\n",
    "                    'Change Type': ['Added', 'Removed', 'Modified'],\n",
    "                    'Count': [\n",
    "                        len(changes[\"added\"]), \n",
    "                        len(changes[\"removed\"]), \n",
    "                        len(changes[\"modified\"])\n",
    "                    ]\n",
    "                })\n",
    "                st.dataframe(\n",
    "                    stats.style.applymap(\n",
    "                        lambda x: f\"background-color: {st.session_state.colors[x.lower()]};\", \n",
    "                        subset=['Change Type']\n",
    "                    ),\n",
    "                    use_container_width=True\n",
    "                )\n",
    "            \n",
    "            with tab3:\n",
    "                st.markdown(full_report, unsafe_allow_html=True)\n",
    "            \n",
    "            with tab4:\n",
    "                st.markdown(summary, unsafe_allow_html=True)\n",
    "                st.write(\"### Change Clusters\")\n",
    "                \n",
    "                if all_clusters:\n",
    "                    for cluster in all_clusters:\n",
    "                        with st.expander(f\"{cluster.get('theme', 'Unnamed Cluster')}\"):\n",
    "                            st.write(f\"**Key Phrases**: {', '.join(cluster.get('key_phrases', []))}\")\n",
    "                            st.write(f\"Associated Changes: {len(cluster.get('change_ids', []))}\")\n",
    "                            st.write(f\"Example Change: {changes[cluster['change_ids'][0]]['content'][:200]}...\")\n",
    "                else:\n",
    "                    st.warning(\"No clusters identified in document changes\")\n",
    "        \n",
    "        # Download button\n",
    "        st.download_button(\n",
    "            label=\"📥 Download Full Report\",\n",
    "            data=full_report,\n",
    "            file_name=\"document_comparison.md\",\n",
    "            mime=\"text/markdown\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- It seems likely that the error \"processing failed: expecting value: line 1 column 1 (char 0)\" occurs due to incorrect JSON parsing in your code, specifically using `json.load` instead of `json.loads` for string parsing.\n",
    "- Research suggests adding error handling and refining the prompt for the AI model can help resolve this issue, ensuring proper JSON formatting.\n",
    "- The evidence leans toward modifying the clustering step in your `generate_executive_summary` function to use `json.loads` and include try-except blocks for robustness.\n",
    "\n",
    "### Why This Error Occurs\n",
    "The error message indicates a JSON parsing failure, likely because your code tries to parse the AI model's response as JSON using `json.load`, which is meant for file objects, not strings. Instead, you should use `json.loads` for parsing strings, which is the correct method for handling the response from the ChatOpenAI model.\n",
    "\n",
    "### How to Fix It\n",
    "To resolve this, modify the clustering part of your `generate_executive_summary` function:\n",
    "- Replace `json.load` with `json.loads` to correctly parse the string response.\n",
    "- Add error handling to catch and display any JSON decoding errors, helping you debug if the AI model returns unexpected output.\n",
    "\n",
    "This approach should prevent the error and make your code more robust against potential issues with the AI model's responses.\n",
    "\n",
    "---\n",
    "\n",
    "### Detailed Analysis and Implementation\n",
    "\n",
    "This section provides a comprehensive examination of the issue, including the root cause, proposed solutions, and additional considerations for enhancing your document comparison pipeline. The analysis is grounded in the code provided and aims to address the error \"processing failed: expecting value: line 1 column 1 (char 0)\" during the summary generation phase.\n",
    "\n",
    "#### Understanding the Error\n",
    "The error message \"expecting value: line 1 column 1 (char 0)\" is a standard JSON decoding error in Python, indicating that the `json` module expected a valid JSON value but encountered an empty string or invalid input at the start. This typically occurs when attempting to parse a string that is not properly formatted as JSON. In your code, this error manifests during the `generate_executive_summary` function, specifically in the clustering step where the response from the ChatOpenAI model is parsed.\n",
    "\n",
    "The root cause appears to be the use of `json.load` instead of `json.loads` for parsing the model's response. In Python's `json` module:\n",
    "- `json.load(fp)` is designed for reading JSON from a file-like object.\n",
    "- `json.loads(s)` is intended for parsing JSON from a string.\n",
    "\n",
    "Given that `cluster_result.content` is a string (the response from the ChatOpenAI model), using `json.load` is incorrect and likely causes the parsing failure, especially if the string is empty or malformed.\n",
    "\n",
    "#### Code Analysis\n",
    "Let's examine the relevant part of your code in the `generate_executive_summary` function:\n",
    "\n",
    "```python\n",
    "for chunk in chunk_changes(\n",
    "    [c for cat in changes.values() for c in cat], \n",
    "    max_tokens=6000\n",
    "):\n",
    "    cluster_result = retriable_chain_ininvoke(cluster_chain, {\n",
    "        \"changes\": \"\\n\".join(\n",
    "            f\"{idx}: {item['content'][:500]}...\" \n",
    "            for idx, item in enumerate(chunk)\n",
    "        )\n",
    "    })\n",
    "    cluster_result_content = cluster_result.content.strip()\n",
    "    try:\n",
    "        parsed_result = json.load(cluster_result.content)  # Incorrect: should be json.loads\n",
    "        all_clusters.extend(parsed_result)\n",
    "    except json.decoder.JsonDecodeError as e:\n",
    "        st.error(f\"Failed to parse clustering result: {e}\")\n",
    "        st.error(f\"Response from model: {cluster_result_content}\")\n",
    "        return\n",
    "```\n",
    "\n",
    "The line `json.load(cluster_result.content)` is problematic because:\n",
    "- `cluster_result.content` is a string, not a file-like object, making `json.load` inappropriate.\n",
    "- This mismatch likely results in the \"expecting value\" error, especially if the string is empty or not a valid JSON.\n",
    "\n",
    "Additionally, the code snippet in the thinking trace suggests a potential syntax error (`all_clusters.extend json.load(cluster_result.content)` without parentheses), but assuming it's a formatting issue, the core problem is the use of `json.load`.\n",
    "\n",
    "#### Proposed Solution\n",
    "To fix this, we recommend the following modifications:\n",
    "\n",
    "1. **Correct JSON Parsing**:\n",
    "   - Replace `json.load(cluster_result.content)` with `json.loads(cluster_result.content)` to properly parse the string response.\n",
    "   - Ensure the `json` module is imported at the top of your file: `import json`.\n",
    "\n",
    "2. **Enhance Error Handling**:\n",
    "   - Keep the try-except block to catch `json.decoder.JsonDecodeError`, which will help identify if the AI model returns unexpected output.\n",
    "   - Strip any leading or trailing whitespace from `cluster_result.content` before parsing, as done in your code (`cluster_result.content.strip()`), to handle potential formatting issues.\n",
    "\n",
    "3. **Refine the Prompt for Clarity**:\n",
    "   - Modify the `cluster_prompt` to explicitly instruct the model to return only a valid JSON array, reducing the chance of extraneous text. For example:\n",
    "\n",
    "```python\n",
    "cluster_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert in data clustering and JSON formatting. Your task is to cluster the following document changes into logical groups based on their semantic similarity. Each change is labeled with an index and a snippet of its content.\n",
    "\n",
    "Changes:\n",
    "{changes}\n",
    "\n",
    "Your response should be a JSON array of cluster objects, where each cluster object has:\n",
    "- \"theme\": a short descriptive title for the cluster\n",
    "- \"change_ids\": an array of the original change indices that belong to this cluster\n",
    "- \"key_phrases\": an array of 3-5 key phrases that summarize the cluster\n",
    "\n",
    "Do not include any additional text or explanations in your response. The output should be a valid JSON array.\n",
    "\n",
    "Example of expected output:\n",
    "[\n",
    "    {\n",
    "        \"theme\": \"Example Cluster\",\n",
    "        \"change_ids\": [0, 2, 3],\n",
    "        \"key_phrases\": [\"phrase1\", \"phrase2\", \"phrase3\"]\n",
    "    },\n",
    "    {\n",
    "        \"theme\": \"Another Cluster\",\n",
    "        \"change_ids\": [1, 4],\n",
    "        \"key_phrases\": [\"phrase4\", \"phrase5\"]\n",
    "    }\n",
    "]\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "This enhanced prompt includes an example, which can help the model generate the correct JSON format, reducing parsing errors.\n",
    "\n",
    "#### Implementation Details\n",
    "Here’s how the modified code should look in the `generate_executive_summary` function:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "# ... (rest of the function remains the same)\n",
    "\n",
    "for chunk in chunk_changes(\n",
    "    [c for cat in changes.values() for c in cat], \n",
    "    max_tokens=6000\n",
    "):\n",
    "    cluster_result = retriable_chain_ininvoke(cluster_chain, {\n",
    "        \"changes\": \"\\n\".join(\n",
    "            f\"{idx}: {item['content'][:500]}...\" \n",
    "            for idx, item in enumerate(chunk)\n",
    "        )\n",
    "    })\n",
    "    cluster_result_content = cluster_result.content.strip()\n",
    "    try:\n",
    "        parsed_result = json.loads(cluster_result_content)  # Corrected to json.loads\n",
    "        all_clusters.extend(parsed_result)\n",
    "    except json.decoder.JsonDecodeError as e:\n",
    "        st.error(f\"Failed to parse clustering result: {e}\")\n",
    "        st.error(f\"Response from model: {cluster_result_content}\")\n",
    "        return\n",
    "\n",
    "# ... (rest of the function remains the same)\n",
    "```\n",
    "\n",
    "#### Additional Considerations\n",
    "- **Model Response Validation**: The error could also occur if the ChatOpenAI model does not return a valid JSON string, possibly due to the input being too complex or the model's temperature setting. Your current setting (`temperature=0.1`) is low, which helps, but ensuring the input (`changes`) is within token limits (chunked at 6000 tokens) is crucial.\n",
    "- **Debugging Tip**: If the error persists, the error handling will display the model's response, allowing you to inspect it for any unexpected text (e.g., introductory remarks before the JSON) and refine the prompt further.\n",
    "- **Performance Impact**: Adding error handling and refining the prompt should not significantly impact performance, as the changes are localized to the parsing step.\n",
    "\n",
    "#### Comparative Analysis of JSON Parsing Methods\n",
    "\n",
    "To illustrate the difference, here’s a table comparing `json.load` and `json.loads`:\n",
    "\n",
    "| Method       | Input Type          | Use Case                              | Example Usage                          |\n",
    "|--------------|---------------------|---------------------------------------|----------------------------------------|\n",
    "| `json.load`  | File-like object    | Reading JSON from a file              | `json.load(open('file.json', 'r'))`    |\n",
    "| `json.loads` | String              | Parsing JSON from a string            | `json.loads('{\"key\": \"value\"}')`       |\n",
    "\n",
    "This table highlights why `json.loads` is the appropriate choice for parsing `cluster_result.content`, which is a string.\n",
    "\n",
    "#### Unexpected Detail: Prompt Engineering Impact\n",
    "An unexpected aspect is how refining the prompt with an example can significantly improve the model's output, potentially reducing parsing errors. This is not immediately obvious but can be critical for ensuring the AI model adheres to the expected JSON format, especially for complex tasks like clustering document changes.\n",
    "\n",
    "#### Conclusion\n",
    "By correcting the JSON parsing method to `json.loads`, adding robust error handling, and refining the prompt for clarity, you should resolve the \"expecting value\" error and enhance the reliability of your document comparison pipeline. This approach ensures your code can handle potential issues with the AI model's responses and provides better debugging capabilities.\n",
    "\n",
    "### Key Citations\n",
    "- [Python JSON Module Documentation](https://docs.python.org/3/library/json.html)\n",
    "- [LangChain ChatOpenAI Documentation](https://python.langchain.com/docs/integrations/chat/openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'st_diff_viewer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mst_diff_viewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m diff_viewer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'st_diff_viewer'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from st_diff_viewer import diff_viewer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "from PyPDF2 import PdfReader\n",
    "import time\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type\n",
    ")\n",
    "import tiktoken\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Custom theme\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    [data-testid=stSidebar] { background-color: #f0f2f6; }\n",
    "    .stProgress > div > div > div > div { background-color: #4B8BF5; }\n",
    "    .st-b7 { color: #262730; }\n",
    "    .report-section { border-left: 4px solid #4B8BF5; padding-left: 1rem; margin: 1rem 0; }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Retry configuration\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    retry=retry_if_exception_type(openai.RateLimitError),\n",
    "    reraise=True\n",
    ")\n",
    "def retriable_chain_invoke(chain, inputs):\n",
    "    return chain.invoke(inputs)\n",
    "\n",
    "def num_tokens(text):\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def extract_text(file):\n",
    "    if file.name.endswith('.docx'):\n",
    "        return docx2txt.process(file)\n",
    "    elif file.name.endswith('.pdf'):\n",
    "        reader = PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def process_document(file, doc_type, year):\n",
    "    text = extract_text(file)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return [{\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"source\": file.name,\n",
    "            \"doc_type\": doc_type,\n",
    "            \"year\": year,\n",
    "            \"page\": (idx // 10) + 1\n",
    "        }\n",
    "    } for idx, chunk in enumerate(chunks)]\n",
    "\n",
    "def analyze_changes(doc1_chunks, doc2_chunks):\n",
    "    embeddings = OpenAIEmbeddings(chunk_size=10)\n",
    "    doc1_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) for c in doc1_chunks]\n",
    "    doc2_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) for c in doc2_chunks]\n",
    "    db1 = FAISS.from_documents(doc1_docs, embeddings)\n",
    "    time.sleep(1)\n",
    "    db2 = FAISS.from_documents(doc2_docs, embeddings)\n",
    "    changes = {\"added\": [], \"removed\": [], \"modified\": []}\n",
    "    batch_size = 5\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"added\"].append({\"content\": doc.page_content, \"metadata\": doc.metadata})\n",
    "        time.sleep(1)\n",
    "    for i in range(0, len(doc1_docs), batch_size):\n",
    "        batch = doc1_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db2.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"removed\"].append({\"content\": doc.page_content, \"metadata\": doc.metadata})\n",
    "        time.sleep(1)\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if similar and similar[0].metadata[\"source\"] == doc.metadata[\"source\"]:\n",
    "                doc1 = similar[0]\n",
    "                if doc1.page_content != doc.page_content:\n",
    "                    changes[\"modified\"].append({\n",
    "                        \"original\": doc1.page_content,\n",
    "                        \"updated\": doc.page_content,\n",
    "                        \"metadata\": doc.metadata\n",
    "                    })\n",
    "        time.sleep(1)\n",
    "    return changes\n",
    "\n",
    "def generate_executive_summary(changes, doc1_meta, doc2_meta):\n",
    "    cluster_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an expert in data clustering and JSON formatting. Your task is to cluster the following document changes into logical groups based on their semantic similarity. Each change is labeled with an index and a snippet of its content.\n",
    "\n",
    "    Changes:\n",
    "    {changes}\n",
    "\n",
    "    Your response MUST be a valid JSON array of cluster objects, where each cluster object has:\n",
    "    - \"theme\": a short descriptive title for the cluster (string)\n",
    "    - \"change_ids\": an array of the original change indices that belong to this cluster (array of integers)\n",
    "    - \"key_phrases\": an array of 3-5 key phrases that summarize the cluster (array of strings)\n",
    "\n",
    "    If there are no changes to cluster or if clustering cannot be performed, return an empty JSON array: [].\n",
    "    Do not include any additional text, explanations, or comments outside the JSON array. The output must be valid JSON.\n",
    "\n",
    "    Example of expected output:\n",
    "    [\n",
    "        {{\n",
    "            \"theme\": \"Policy Updates\",\n",
    "            \"change_ids\": [0, 2, 3],\n",
    "            \"key_phrases\": [\"new regulation\", \"compliance\", \"deadline\"]\n",
    "        }},\n",
    "        {{\n",
    "            \"theme\": \"Formatting Changes\",\n",
    "            \"change_ids\": [1, 4],\n",
    "            \"key_phrases\": [\"font size\", \"layout\", \"spacing\"]\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\")\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    As a professional analyst, create an executive summary comparing:\n",
    "    {doc1} ({year1}) vs {doc2} ({year2}).\n",
    "    \n",
    "    Key clustered changes:\n",
    "    {clustered_changes}\n",
    "\n",
    "    Structure:\n",
    "    1. *Major Structural Changes* (sections added/removed)\n",
    "    2. *Content Evolution* (modified themes and concepts)\n",
    "    3. *Strategic Implications* (business impact analysis)\n",
    "    4. *Recommendations* (next steps based on changes)\n",
    "    \n",
    "    Include specific examples with citations like: \n",
    "    \"The address changed from [X][p3] to [Y][p12]\" \n",
    "    Use markdown with section headers and bold key terms.\n",
    "    \"\"\")\n",
    "    cluster_chain = cluster_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.1)\n",
    "    summary_chain = summary_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    def chunk_changes(changes, max_tokens=6000):\n",
    "        current_chunk = []\n",
    "        current_count = 0\n",
    "        for idx, item in enumerate(changes):\n",
    "            item_tokens = num_tokens(item['content'])\n",
    "            if current_count + item_tokens > max_tokens:\n",
    "                yield current_chunk\n",
    "                current_chunk = []\n",
    "                current_count = 0\n",
    "            current_chunk.append((idx, item))\n",
    "            current_count += item_tokens\n",
    "        if current_chunk:\n",
    "            yield current_chunk\n",
    "\n",
    "    flat_changes = [c for cat in changes.values() for c in cat]\n",
    "    if not flat_changes:\n",
    "        st.warning(\"No changes detected to cluster.\")\n",
    "        return \"No significant changes detected between documents.\", [], flat_changes\n",
    "\n",
    "    all_clusters = []\n",
    "    for chunk in chunk_changes(flat_changes, max_tokens=6000):\n",
    "        changes_input = \"\\n\".join(f\"{idx}: {item['content'][:500]}...\" for idx, item in chunk)\n",
    "        if not changes_input.strip():\n",
    "            st.warning(\"Empty chunk encountered; skipping.\")\n",
    "            all_clusters.append([])  # Append empty cluster for this chunk\n",
    "            continue\n",
    "\n",
    "        cluster_result = retriable_chain_invoke(cluster_chain, {\"changes\": changes_input})\n",
    "        cluster_result_content = cluster_result.content.strip()\n",
    "        st.write(f\"DEBUG: Model response for chunk: '{cluster_result_content}'\")  # Debug output\n",
    "\n",
    "        try:\n",
    "            parsed_result = json.loads(cluster_result_content)\n",
    "            if not isinstance(parsed_result, list):\n",
    "                raise ValueError(\"Model response is not a JSON array\")\n",
    "            all_clusters.extend(parsed_result)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            st.error(f\"Failed to parse clustering result: {e}\")\n",
    "            st.error(f\"Raw response from model: '{cluster_result_content}'\")\n",
    "            all_clusters.extend([])  # Fallback to empty cluster\n",
    "            continue\n",
    "\n",
    "    cluster_summaries = []\n",
    "    for cluster in all_clusters:\n",
    "        if not cluster or \"change_ids\" not in cluster:\n",
    "            continue\n",
    "        cluster_changes = [flat_changes[i] for i in cluster[\"change_ids\"] if i < len(flat_changes)]\n",
    "        cluster_text = \"\\n\".join(\n",
    "            f\"Change {i}: {c['content'][:1000]} [Source: {c['metadata']['source']}, Page {c['metadata']['page']}]\"\n",
    "            for i, c in zip(cluster[\"change_ids\"], cluster_changes)\n",
    "        )\n",
    "        cluster_summary = retriable_chain_invoke(summary_chain, {\n",
    "            \"doc1\": doc1_meta[\"name\"],\n",
    "            \"year1\": doc1_meta[\"year\"],\n",
    "            \"doc2\": doc2_meta[\"name\"],\n",
    "            \"year2\": doc2_meta[\"year\"],\n",
    "            \"clustered_changes\": cluster_text if cluster_text else \"No changes in this cluster\"\n",
    "        })\n",
    "        cluster_summaries.append(cluster_summary.content)\n",
    "        time.sleep(1)\n",
    "\n",
    "    final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Synthesize these cluster summaries into an executive report:\n",
    "    {cluster_summaries}\n",
    "\n",
    "    Maintain this structure:\n",
    "    1. *Document Evolution Overview*\n",
    "    2. *Strategic Direction Analysis*\n",
    "    3. *Operational Impact Assessment*\n",
    "    4. *Recommendations for Future Versions*\n",
    "\n",
    "    Include 3-5 key visualizable trends using *bold* terms.\n",
    "    Cite sources like [Source: {{source}}, Page {{page}}].\n",
    "    \"\"\")\n",
    "    final_chain = final_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
    "    final_summary = retriable_chain_invoke(final_chain, {\n",
    "        \"cluster_summaries\": \"\\n\\n\".join(cluster_summaries) if cluster_summaries else \"No significant changes detected.\"\n",
    "    })\n",
    "    return final_summary.content, all_clusters, flat_changes\n",
    "\n",
    "def generate_detailed_report(changes, doc1_meta, doc2_meta):\n",
    "    report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Analyze document changes between:\n",
    "    {doc1} ({year1}) and {doc2} ({year2})\n",
    "\n",
    "    Changes:\n",
    "    {changes}\n",
    "\n",
    "    Format requirements:\n",
    "    - Group by ADDED/REMOVED/MODIFIED\n",
    "    - Include citations like [Source: {{source}}, Page {{page}}]\n",
    "    - Highlight significant changes with *bold*\n",
    "    - Use markdown headers ##\n",
    "    - Maintain academic tone\n",
    "    \"\"\")\n",
    "    full_report = []\n",
    "    chain = report_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.2, max_tokens=4000)\n",
    "    for chunk in chunked_report_generator(changes):\n",
    "        part = retriable_chain_invoke(chain, {\n",
    "            \"doc1\": doc1_meta[\"name\"],\n",
    "            \"year1\": doc1_meta[\"year\"],\n",
    "            \"doc2\": doc2_meta[\"name\"],\n",
    "            \"year2\": doc2_meta[\"year\"],\n",
    "            \"changes\": \"\\n\".join(chunk)\n",
    "        }).content\n",
    "        full_report.append(part)\n",
    "        time.sleep(2)\n",
    "    return \"\\n\\n\".join(full_report)\n",
    "\n",
    "def chunked_report_generator(changes, max_tokens=12000):\n",
    "    current_chunk = []\n",
    "    current_count = 0\n",
    "    for cat in ['added', 'removed', 'modified']:\n",
    "        for item in changes[cat]:\n",
    "            content = f\"{cat.upper()}:\\n{item['content']}\\n\"\n",
    "            tokens = num_tokens(content)\n",
    "            if current_count + tokens > max_tokens:\n",
    "                yield current_chunk\n",
    "                current_chunk = []\n",
    "                current_count = 0\n",
    "            current_chunk.append(content)\n",
    "            current_count += tokens\n",
    "    if current_chunk:\n",
    "        yield current_chunk\n",
    "\n",
    "def main():\n",
    "    st.title(\"Professional Document Comparison Suite\")\n",
    "    if 'colors' not in st.session_state:\n",
    "        st.session_state.colors = {'added': '#d4f7d4', 'removed': '#f7d4d4', 'modified': '#fff3d4'}\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header(\"Configuration\")\n",
    "        st.session_state.colors['added'] = st.color_picker(\"Added Color\", '#d4f7d4')\n",
    "        st.session_state.colors['removed'] = st.color_picker(\"Removed Color\", '#f7d4d4')\n",
    "        st.session_state.colors['modified'] = st.color_picker(\"Modified Color\", '#fff3d4')\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        doc1 = st.file_uploader(\"Upload Baseline Document\", type=[\"pdf\", \"docx\"])\n",
    "        year1 = st.number_input(\"Baseline Year\", min_value=1900, max_value=2025, value=2023)\n",
    "    with col2:\n",
    "        doc2 = st.file_uploader(\"Upload Comparison Document\", type=[\"pdf\", \"docx\"])\n",
    "        year2 = st.number_input(\"Comparison Year\", min_value=1900, max_value=2025, value=2024)\n",
    "\n",
    "    if st.button(\"Analyze Documents\") and doc1 and doc2:\n",
    "        with st.status(\"Processing documents...\", expanded=True) as status:\n",
    "            try:\n",
    "                st.write(\"📄 Processing Document 1...\")\n",
    "                doc1_chunks = process_document(doc1, doc1.name.split('.')[-1], year1)\n",
    "                st.write(\"📄 Processing Document 2...\")\n",
    "                doc2_chunks = process_document(doc2, doc2.name.split('.')[-1], year2)\n",
    "                st.write(\"🔍 Analyzing differences...\")\n",
    "                changes = analyze_changes(doc1_chunks, doc2_chunks)\n",
    "                st.write(\"📊 Generating summary...\")\n",
    "                summary, all_clusters, flat_changes = generate_executive_summary(\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    "                )\n",
    "                st.write(\"📝 Compiling detailed report...\")\n",
    "                detailed_report = generate_detailed_report(\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    "                )\n",
    "                full_report = f\"# Document Comparison Report\\n{summary}\\n{detailed_report}\"\n",
    "                status.update(label=\"Analysis complete! ✅\", state=\"complete\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"❌ Processing failed: {str(e)}\")\n",
    "                return\n",
    "                         \n",
    "        with st.expander(\"Detailed Analysis\", expanded=True):\n",
    "            tab1, tab2, tab3, tab4 = st.tabs([\"Diff View\", \"Statistics\", \"Full Report\", \"Executive Summary\"])\n",
    "            with tab1:\n",
    "                diff_viewer(\n",
    "                    \"\\n\".join([c[\"content\"] for c in changes[\"removed\"]]),\n",
    "                    \"\\n\".join([c[\"content\"] for c in changes[\"added\"]]),\n",
    "                    split_view=True,\n",
    "                    added_style=f\"background: {st.session_state.colors['added']}\",\n",
    "                    removed_style=f\"background: {st.session_state.colors['removed']}\",\n",
    "                    modified_style=f\"background: {st.session_state.colors['modified']}\"\n",
    "                )\n",
    "            with tab2:\n",
    "                stats = pd.DataFrame({\n",
    "                    'Change Type': ['Added', 'Removed', 'Modified'],\n",
    "                    'Count': [len(changes[\"added\"]), len(changes[\"removed\"]), len(changes[\"modified\"])]\n",
    "                })\n",
    "                st.dataframe(\n",
    "                    stats.style.applymap(\n",
    "                        lambda x: f\"background-color: {st.session_state.colors[x.lower()]};\",\n",
    "                        subset=['Change Type']\n",
    "                    ),\n",
    "                    use_container_width=True\n",
    "                )\n",
    "            with tab3:\n",
    "                st.markdown(full_report, unsafe_allow_html=True)\n",
    "            with tab4:\n",
    "                st.markdown(summary, unsafe_allow_html=True)\n",
    "                st.write(\"### Change Clusters\")\n",
    "                if all_clusters:\n",
    "                    for cluster in all_clusters:\n",
    "                        if not cluster or \"theme\" not in cluster:\n",
    "                            continue\n",
    "                        with st.expander(f\"{cluster.get('theme', 'Unnamed Cluster')}\"):\n",
    "                            st.write(f\"*Key Phrases*: {', '.join(cluster.get('key_phrases', []))}\")\n",
    "                            st.write(f\"Associated Changes: {len(cluster.get('change_ids', []))}\")\n",
    "                            if cluster.get('change_ids'):  # Check if change_ids exists and is not empty\n",
    "                                st.write(f\"Example Change: {flat_changes[cluster['change_ids'][0]]['content'][:200]}...\")\n",
    "                else:\n",
    "                    st.warning(\"No clusters identified in document changes\")\n",
    "\n",
    "        st.download_button(\n",
    "            label=\"📥 Download Full Report\",\n",
    "            data=full_report,\n",
    "            file_name=\"document_comparison.md\",\n",
    "            mime=\"text/markdown\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from st_diff_viewer import diff_viewer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "from PyPDF2 import PdfReader\n",
    "import time\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type\n",
    ")\n",
    "import tiktoken\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Custom theme\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    [data-testid=stSidebar] { background-color: #f0f2f6; }\n",
    "    .stProgress > div > div > div > div { background-color: #4B8BF5; }\n",
    "    .st-b7 { color: #262730; }\n",
    "    .report-section { border-left: 4px solid #4B8BF5; padding-left: 1rem; margin: 1rem 0; }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Retry configuration\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    retry=retry_if_exception_type(openai.RateLimitError),\n",
    "    reraise=True\n",
    ")\n",
    "def retriable_chain_invoke(chain, inputs):\n",
    "    return chain.invoke(inputs)\n",
    "\n",
    "def num_tokens(text):\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def extract_text(file):\n",
    "    if file.name.endswith('.docx'):\n",
    "        return docx2txt.process(file)\n",
    "    elif file.name.endswith('.pdf'):\n",
    "        reader = PdfReader(file)\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def process_document(file, doc_type, year):\n",
    "    text = extract_text(file)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return [{\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"source\": file.name,\n",
    "            \"doc_type\": doc_type,\n",
    "            \"year\": year,\n",
    "            \"page\": (idx // 10) + 1\n",
    "        }\n",
    "    } for idx, chunk in enumerate(chunks)]\n",
    "\n",
    "def analyze_changes(doc1_chunks, doc2_chunks):\n",
    "    embeddings = OpenAIEmbeddings(chunk_size=10)\n",
    "    doc1_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) for c in doc1_chunks]\n",
    "    doc2_docs = [Document(page_content=c[\"text\"], metadata=c[\"metadata\"]) for c in doc2_chunks]\n",
    "    db1 = FAISS.from_documents(doc1_docs, embeddings)\n",
    "    time.sleep(1)\n",
    "    db2 = FAISS.from_documents(doc2_docs, embeddings)\n",
    "    \n",
    "    changes = {\"added\": [], \"removed\": [], \"modified\": []}\n",
    "    \n",
    "    batch_size = 5\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"added\"].append({\"content\": doc.page_content, \"metadata\": doc.metadata})\n",
    "        time.sleep(1)\n",
    "\n",
    "    for i in range(0, len(doc1_docs), batch_size):\n",
    "        batch = doc1_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db2.similarity_search(doc.page_content, k=1)\n",
    "            if not similar or similar[0].metadata[\"source\"] != doc.metadata[\"source\"]:\n",
    "                changes[\"removed\"].append({\"content\": doc.page_content, \"metadata\": doc.metadata})\n",
    "        time.sleep(1)\n",
    "\n",
    "    for i in range(0, len(doc2_docs), batch_size):\n",
    "        batch = doc2_docs[i:i+batch_size]\n",
    "        for doc in batch:\n",
    "            similar = db1.similarity_search(doc.page_content, k=1)\n",
    "            if similar and similar[0].metadata[\"source\"] == doc.metadata[\"source\"]:\n",
    "                doc1 = similar[0]\n",
    "                if doc1.page_content != doc.page_content:\n",
    "                    changes[\"modified\"].append({\n",
    "                        \"original\": doc1.page_content,\n",
    "                        \"updated\": doc.page_content,\n",
    "                        \"metadata\": doc.metadata\n",
    "                    })\n",
    "        time.sleep(1)\n",
    "\n",
    "    return changes\n",
    "\n",
    "def generate_executive_summary(changes, doc1_meta, doc2_meta):\n",
    "    cluster_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an expert in data clustering and JSON formatting. Your task is to cluster the following document changes into logical groups based on their semantic similarity. Each change is labeled with an index and a snippet of its content.\n",
    "\n",
    "    Changes:\n",
    "    {changes}\n",
    "\n",
    "    Your response MUST be a valid JSON array of cluster objects, where each cluster object has:\n",
    "    - \"theme\": a short descriptive title for the cluster (string)\n",
    "    - \"change_ids\": an array of the original change indices that belong to this cluster (array of integers)\n",
    "    - \"key_phrases\": an array of 3-5 key phrases that summarize the cluster (array of strings)\n",
    "\n",
    "    If there are no changes to cluster or if clustering cannot be performed, return an empty JSON array: [].\n",
    "    Do not include any additional text, explanations, or comments outside the JSON array. The output must be valid JSON.\n",
    "\n",
    "    Example of expected output:\n",
    "    [\n",
    "        {{\n",
    "            \"theme\": \"Policy Updates\",\n",
    "            \"change_ids\": [0, 2, 3],\n",
    "            \"key_phrases\": [\"new regulation\", \"compliance\", \"deadline\"]\n",
    "        }},\n",
    "        {{\n",
    "            \"theme\": \"Formatting Changes\",\n",
    "            \"change_ids\": [1, 4],\n",
    "            \"key_phrases\": [\"font size\", \"layout\", \"spacing\"]\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\")\n",
    "    \n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    As a professional analyst, create an executive summary comparing:\n",
    "    {doc1} ({year1}) vs {doc2} ({year2}).\n",
    "    \n",
    "    Key clustered changes:\n",
    "    {clustered_changes}\n",
    "\n",
    "    Structure:\n",
    "    1. Major Structural Changes (sections added/removed)\n",
    "    2. Content Evolution (modified themes and concepts)\n",
    "    3. Strategic Implications (business impact analysis)\n",
    "    4. Recommendations (next steps based on changes)\n",
    "    \n",
    "    Include specific examples with citations like: \n",
    "    \"The address changed from [X][p3] to [Y][p12]\" \n",
    "    Use markdown with section headers and bold key terms.\n",
    "    \"\"\")\n",
    "    \n",
    "    cluster_chain = cluster_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.1)\n",
    "    summary_chain = summary_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.1)\n",
    "    \n",
    "    def chunk_changes(changes, max_tokens=6000):\n",
    "        current_chunk = []\n",
    "        current_count = 0\n",
    "        \n",
    "        for idx, item in enumerate(changes):\n",
    "            item_tokens = num_tokens(item['content'])\n",
    "            if current_count + item_tokens > max_tokens:\n",
    "                yield current_chunk\n",
    "                current_chunk = []\n",
    "                current_count = 0\n",
    "            \n",
    "            current_chunk.append((idx, item))\n",
    "            current_count += item_tokens\n",
    "        \n",
    "        if current_chunk:\n",
    "            yield current_chunk\n",
    "\n",
    "    \n",
    "    flat_changes = [c for cat in changes.values() for c in cat]\n",
    "    \n",
    "    if not flat_changes:\n",
    "        st.warning(\"No changes detected to cluster.\")\n",
    "        return \"No significant changes detected between documents.\", [], flat_changes\n",
    "\n",
    "    all_clusters = []\n",
    "    for chunk in chunk_changes(flat_changes, max_tokens=6000):\n",
    "        changes_input = \"\\n\".join(f\"{idx}: {item['content'][:500]}...\" for idx, item in chunk)\n",
    "        if not changes_input.strip():\n",
    "            st.warning(\"Empty chunk encountered; skipping.\")\n",
    "            all_clusters.append([])  \n",
    "            continue\n",
    "\n",
    "        cluster_result = retriable_chain_invoke(cluster_chain, {\"changes\": changes_input})\n",
    "        cluster_result_content = cluster_result.content.strip()\n",
    "        st.write(f\"DEBUG: Model response for chunk: '{cluster_result_content}'\")  \n",
    "\n",
    "        try:\n",
    "            parsed_result = json.loads(cluster_result_content)\n",
    "            if not isinstance(parsed_result, list):\n",
    "                raise ValueError(\"Model response is not a JSON array\")\n",
    "            all_clusters.extend(parsed_result)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            st.error(f\"Failed to parse clustering result: {e}\")\n",
    "            st.error(f\"Raw response from model: '{cluster_result_content}'\")\n",
    "            all_clusters.extend([])\n",
    "            \n",
    "    cluster_summaries = []\n",
    "    for cluster in all_clusters:\n",
    "        if not cluster or \"change_ids\" not in cluster:\n",
    "            continue\n",
    "\n",
    "        cluster_changes = [flat_changes[i] for i in cluster[\"change_ids\"] if i < len(flat_changes)]\n",
    "        cluster_text = \"\\n\".join(\n",
    "            f\"Change {i}: {c['content'][:1000]} [Source: {c['metadata']['source']}, Page {c['metadata']['page']}]\"\n",
    "            for i, c in zip(cluster[\"change_ids\"], cluster_changes)\n",
    "        )\n",
    "        \n",
    "        cluster_summary = retriable_chain_invoke(summary_chain, {\n",
    "            \"doc1\": doc1_meta[\"name\"],\n",
    "            \"year1\": doc1_meta[\"year\"],\n",
    "            \"doc2\": doc2_meta[\"name\"],\n",
    "            \"year2\": doc2_meta[\"year\"],\n",
    "            \"clustered_changes\": cluster_text if cluster_text else \"No changes in this cluster\"\n",
    "        })\n",
    "        \n",
    "        cluster_summaries.append(cluster_summary.content)\n",
    "        time.sleep(1)\n",
    "\n",
    "    final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Synthesize these cluster summaries into an executive report:\n",
    "    {cluster_summaries}\n",
    "\n",
    "    Maintain this structure:\n",
    "    1. Document Evolution Overview\n",
    "    2. Strategic Direction Analysis\n",
    "    3. Operational Impact Assessment\n",
    "    4. Recommendations for Future Versions\n",
    "\n",
    "    Include 3-5 key visualizable trends using bold terms.\n",
    "    Cite sources like [Source: {{source}}, Page {{page}}].\n",
    "    \"\"\")\n",
    "   \n",
    "    final_chain = final_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
    "   \n",
    "    final_summary = retriable_chain_invoke(final_chain, {\n",
    "        \"cluster_summaries\": \"\\n\\n\".join(cluster_summaries) if cluster_summaries else \"No significant changes detected.\"\n",
    "    })\n",
    "    \n",
    "    return final_summary.content, all_clusters, flat_changes\n",
    "\n",
    "def generate_detailed_report(changes, doc1_meta, doc2_meta):\n",
    "   report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "   Analyze document changes between:\n",
    "   {doc1} ({year1}) and {doc2} ({year2})\n",
    "\n",
    "   Changes:\n",
    "   {changes}\n",
    "\n",
    "   Format requirements:\n",
    "   - Group by ADDED/REMOVED/MODIFIED\n",
    "   - Include citations like [Source: {{source}}, Page {{page}}]\n",
    "   - Highlight significant changes with bold\n",
    "   - Use markdown headers ##\n",
    "   - Maintain academic tone\n",
    "   \"\"\")\n",
    "   \n",
    "   full_report = []\n",
    "   \n",
    "   chain = report_prompt | ChatOpenAI(model=\"gpt-4\", temperature=0.2, max_tokens=4000)\n",
    "   \n",
    "   for chunk in chunked_report_generator(changes):\n",
    "       part = retriable_chain_invoke(chain, {\n",
    "           \"doc1\": doc1_meta[\"name\"],\n",
    "           \"year1\": doc1_meta[\"year\"],\n",
    "           \"doc2\": doc2_meta[\"name\"],\n",
    "           \"year2\": doc2_meta[\"year\"],\n",
    "           \"changes\": \"\\n\".join(chunk)\n",
    "       }).content\n",
    "      \n",
    "       full_report.append(part)\n",
    "       time.sleep(2)\n",
    "\n",
    "   return \"\\n\\n\".join(full_report)\n",
    "\n",
    "def chunked_report_generator(changes, max_tokens=12000):\n",
    "   current_chunk = []\n",
    "   current_count = 0\n",
    "   \n",
    "   for cat in ['added', 'removed', 'modified']:\n",
    "       for item in changes[cat]:\n",
    "           content = f\"{cat.upper()}:\\n{item['content']}\\n\"\n",
    "           tokens = num_tokens(content)\n",
    "           \n",
    "           if current_count + tokens > max_tokens:\n",
    "               yield current_chunk\n",
    "               current_chunk = []\n",
    "               current_count = 0\n",
    "            \n",
    "           current_chunk.append(content)\n",
    "           current_count += tokens\n",
    "   \n",
    "   if current_chunk:\n",
    "       yield current_chunk\n",
    "def main():\n",
    "    st.title(\"Professional Document Comparison Suite\")\n",
    "   \n",
    "    if 'colors' not in st.session_state:\n",
    "        st.session_state.colors = {'added': '#d4f7d4', 'removed': '#f7d4d4', 'modified': '#fff3d4'}\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header(\"Configuration\")\n",
    "        st.session_state.colors['added'] = st.color_picker(\"Added Color\", '#d4f7d4')\n",
    "        st.session_state.colors['removed'] = st.color_picker(\"Removed Color\", '#f7d4d4')\n",
    "        st.session_state.colors['modified'] = st.color_picker(\"Modified Color\", '#fff3d4')\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "   \n",
    "    with col1:\n",
    "        doc1 = st.file_uploader(\"Upload Baseline Document\", type=[\"pdf\", \"docx\"])\n",
    "        year1 = st.number_input(\"Baseline Year\", min_value=1900, max_value=2025, value=2023)\n",
    "\n",
    "    with col2:\n",
    "        doc2 = st.file_uploader(\"Upload Comparison Document\", type=[\"pdf\", \"docx\"])\n",
    "        year2 = st.number_input(\"Comparison Year\", min_value=1900, max_value=2025, value=2024)\n",
    "\n",
    "    if st.button(\"Analyze Documents\") and doc1 and doc2:\n",
    "        with st.status(\"Processing documents...\", expanded=True) as status:\n",
    "            try:\n",
    "                st.write(\"📄 Processing Document 1...\")\n",
    "                doc1_chunks = process_document(doc1, doc1.name.split('.')[-1], year1)\n",
    "                st.write(\"📄 Processing Document 2...\")\n",
    "                doc2_chunks = process_document(doc2, doc2.name.split('.')[-1], year2)\n",
    "                st.write(\"🔍 Analyzing differences...\")\n",
    "                changes = analyze_changes(doc1_chunks, doc2_chunks)\n",
    "                st.write(\"📊 Generating summary...\")\n",
    "                summary, all_clusters, flat_changes = generate_executive_summary(\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    "                )\n",
    "                st.write(\"📝 Compiling detailed report...\")\n",
    "                detailed_report = generate_detailed_report(\n",
    "                    changes,\n",
    "                    {\"name\": doc1.name, \"year\": year1},\n",
    "                    {\"name\": doc2.name, \"year\": year2}\n",
    "                )\n",
    "               \n",
    "                full_report = f\"# Document Comparison Report\\n{summary}\\n{detailed_report}\"\n",
    "                status.update(label=\"Analysis complete! ✅\", state=\"complete\")\n",
    "\n",
    "                # Display analysis results\n",
    "                                # Display analysis results\n",
    "                tabs = st.tabs([\n",
    "                    \"Diff View\", \n",
    "                    \"Statistics\", \n",
    "                    \"Full Report\", \n",
    "                    \"Executive Summary\",\n",
    "                    \"Change Clusters\"\n",
    "                ])\n",
    "                \n",
    "                with tabs[0]:  # Diff View\n",
    "                    diff_viewer(\n",
    "                        \"\\n\".join([c[\"content\"] for c in changes[\"removed\"]]),\n",
    "                        \"\\n\".join([c[\"content\"] for c in changes[\"added\"]]),\n",
    "                        split_view=True,\n",
    "                        added_style=f\"background: {st.session_state.colors['added']}\",\n",
    "                        removed_style=f\"background: {st.session_state.colors['removed']}\",\n",
    "                        modified_style=f\"background: {st.session_state.colors['modified']}\"\n",
    "                    )\n",
    "                \n",
    "                with tabs[1]:  # Statistics\n",
    "                    stats_df = pd.DataFrame({\n",
    "                        'Change Type': ['Added', 'Removed', 'Modified'],\n",
    "                        'Count': [\n",
    "                            len(changes[\"added\"]), \n",
    "                            len(changes[\"removed\"]), \n",
    "                            len(changes[\"modified\"])\n",
    "                        ]\n",
    "                    })\n",
    "                    st.dataframe(\n",
    "                        stats_df.style.applymap(\n",
    "                            lambda x: f\"background-color: {st.session_state.colors[x.lower()]};\",\n",
    "                            subset=['Change Type']\n",
    "                        ),\n",
    "                        use_container_width=True\n",
    "                    )\n",
    "                \n",
    "                with tabs[2]:  # Full Report\n",
    "                    st.markdown(full_report, unsafe_allow_html=True)\n",
    "\n",
    "                with tabs[3]:  # Executive Summary\n",
    "                    st.markdown(summary.replace(\"\\n\",\"<br>\"), unsafe_allow_html=True)\n",
    "\n",
    "                with tabs[4]:  # Change Clusters\n",
    "                    if all_clusters:\n",
    "                        for cluster in all_clusters:\n",
    "                            if not cluster or \"theme\" not in cluster:\n",
    "                                continue\n",
    "                            \n",
    "                            st.subheader(cluster.get('theme', 'Unnamed Cluster'))\n",
    "                            st.write(f\"Key Phrases: {', '.join(cluster.get('key_phrases', []))}\")\n",
    "                            st.write(f\"Associated Changes: {len(cluster.get('change_ids', []))}\")\n",
    "\n",
    "                            if cluster.get('change_ids'):  \n",
    "                                if st.checkbox(f\"Show Example Change from '{cluster.get('theme', 'Unnamed Cluster')}'\"):\n",
    "                                    example_change_index = cluster['change_ids'][0]\n",
    "                                    example_change = flat_changes[example_change_index]\n",
    "                                    example_content = example_change['content']\n",
    "                                    metadata = example_change['metadata']\n",
    "                                    source_info = f\"[Source: {metadata['source']}, Page {metadata['page']}]\"\n",
    "                                    st.write(f\"{example_content[:200]}... {source_info}\")\n",
    "                    else:\n",
    "                        st.warning(\"No clusters identified in document changes\")\n",
    "\n",
    "                # Download button (outside of tabs)\n",
    "                st.download_button(\n",
    "                    label=\"📥 Download Full Report\",\n",
    "                    data=full_report,\n",
    "                    file_name=\"document_comparison.md\",\n",
    "                    mime=\"text/markdown\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                st.error(f\"❌ Processing failed: {str(e)}\")\n",
    "                return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
